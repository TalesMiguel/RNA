{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi+2K/UnDW1icYcap5pLsJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TalesMiguel/RNA/blob/main/trabalho3_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Redes Neurais Artificiais - Trabalho 3: Autoencoders Variacionais (VAE)**\n",
        "\n",
        "## Feito por:\n",
        "Camilo Maia Pires - 140473\n",
        "Tales Miguel Machado Pereira - 140247\n",
        "\n",
        "## **Introdução**\n",
        "\n",
        "\n",
        "### Autoencoders Variacionais (VAE)\n",
        "\n",
        "Autoencoders Variacionais (VAEs) são modelos generativos que combinam redes neurais com inferência variacional para aprender representações latentes de dados. Eles são compostos por duas partes principais: o **encoder**, que mapeia os dados de entrada para um espaço latente, e o **decoder**, que reconstrói os dados a partir desse resultado. A principal diferença entre VAEs e autoencoders tradicionais é que VAEs aprendem uma distribuição de probabilidade no espaço latente estruturado e contínuo.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Datasets Utilizados\n",
        "\n",
        "Para este trabalho, foram selecionados dois datasets rotulados:\n",
        "\n",
        "1. **Digits Dataset**: Um conjunto de dados que contém imagens de dígitos manuscritos (0 a 9). Cada imagem é representada por uma matriz 8x8 de pixels, resultando em 64 features.\n",
        "\n",
        "2. **Iris Dataset**: Um conjunto de dados clássico que contém 150 amostras de flores Iris, com 4 features cada (comprimento e largura das sépalas e pétalas) e 3 classes (Setosa, Versicolour e Virginica).\n",
        "\n",
        "<br>\n",
        "\n",
        "### Objetivo\n",
        "\n",
        "O objetivo deste trabalho é treinar modelos VAEs nesses datasets, explorar o espaço latente gerado e analisar a formação de clusters e a separação dos rótulos nesse espaço. Além disso, será avaliado quanto da variância dos dados é capturada pela projeção do espaço latente em 2D usando PCA.\n",
        "\n",
        "Adicionalmente, tentaremos enviesar a formação do espaço latente com os exemplos previamente rotulados.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "sQdvbvgxmSLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Implementação\n",
        "\n",
        "### Importação de Bibliotecas\n",
        "\n"
      ],
      "metadata": {
        "id": "DDKhRmzq7OTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras import layers, models, losses\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "iCMTrE6463hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregamento dos Datasets"
      ],
      "metadata": {
        "id": "hjKZwmCy7bMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digits Dataset\n",
        "digits = datasets.load_digits()\n",
        "X_digits = digits.data      # Features\n",
        "y_digits = digits.target    # Rótulos\n",
        "\n",
        "# Iris Dataset\n",
        "iris = datasets.load_iris()\n",
        "X_iris = iris.data          # Features\n",
        "y_iris = iris.target        # Rótulos"
      ],
      "metadata": {
        "id": "kQ-5u-XD7fYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pré-processamento dos Dados\n",
        "\n",
        "Antes de treinar o VAE, precisamos normalizar os dados para garantir que todas suas features estejam na mesma escala."
      ],
      "metadata": {
        "id": "bsGVsdRr81aN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_digits_scaled = StandardScaler().fit_transform(X_digits)\n",
        "X_iris_scaled = StandardScaler().fit_transform(X_iris)"
      ],
      "metadata": {
        "id": "ozfUkE2T8_i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construção do Modelo VAE\n",
        "\n",
        "A seguir, definimos a arquitetura do VAE. O encoder mapeia os dados de entrada para o espaço latente, enquanto o decoder tenta reconstruir os dados a partir desse espaço."
      ],
      "metadata": {
        "id": "gPke1Kaa9T5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parâmetros do VAE\n",
        "input_dim_digits = X_digits_scaled.shape[1]\n",
        "input_dim_iris = X_iris_scaled.shape[1]\n",
        "latent_dim = 2  # Dimensão do espaço latente\n",
        "\n",
        "# Função de perda do VAE\n",
        "def vae_loss(x, x_decoded_mean):\n",
        "    reconstruction_loss = losses.mse(x, x_decoded_mean)\n",
        "    kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "    return K.mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "# Encoder\n",
        "inputs = layers.Input(shape=(input_dim_digits,))\n",
        "x = layers.Dense(128, activation='relu')(inputs)\n",
        "z_mean = layers.Dense(latent_dim)(x)\n",
        "z_log_var = layers.Dense(latent_dim)(x)\n",
        "\n",
        "# Amostragem no espaço latente\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "# Decoder\n",
        "decoder_input = layers.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(128, activation='relu')(decoder_input)\n",
        "outputs = layers.Dense(input_dim_digits, activation='sigmoid')(x)\n",
        "\n",
        "# Modelos\n",
        "encoder = models.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "decoder = models.Model(decoder_input, outputs, name='decoder')\n",
        "vae_outputs = decoder(encoder(inputs)[2])\n",
        "vae = models.Model(inputs, vae_outputs, name='vae')\n",
        "\n",
        "# Compilação do modelo\n",
        "vae.compile(optimizer='adam', loss=vae_loss)\n"
      ],
      "metadata": {
        "id": "H_JNCpL99aSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinamento do VAE\n",
        "\n",
        "Treinamos o VAE no Digits Dataset e no Iris Dataset.\n"
      ],
      "metadata": {
        "id": "MvlYPWp0-U_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinamento no Digits Dataset\n",
        "vae.fit(X_digits_scaled, X_digits_scaled, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Treinamento no Iris Dataset\n",
        "vae.fit(X_iris_scaled, X_iris_scaled, epochs=50, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "i_jD-h8Y-TVg",
        "outputId": "56937ad2-b9f5-4eff-85e5-e075b0ebf3ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Tried to convert 'x' to a tensor and failed. Error: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9f269f5c982b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Treinamento no Digits Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_digits_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_digits_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Treinamento no Iris Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_iris_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_iris_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-309738a4327c>\u001b[0m in \u001b[0;36mvae_loss\u001b[0;34m(x, x_decoded_mean)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_decoded_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mreconstruction_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_decoded_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mkl_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mz_log_var\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_log_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstruction_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkl_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tried to convert 'x' to a tensor and failed. Error: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploração do Espaço Latente\n",
        "\n",
        "Após o treinamento, exploramos o espaço latente gerado pelo VAE. Para isso, projetamos o espaço latente em 2D usando PCA e visualizamos a formação de clusters.\n"
      ],
      "metadata": {
        "id": "6ePdNuOl-3sT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Projeção do espaço latente em 2D usando PCA\n",
        "def plot_latent_space(encoder, X, y, title):\n",
        "    z_mean, _, _ = encoder.predict(X)\n",
        "    pca = PCA(n_components=2)\n",
        "    z_pca = pca.fit_transform(z_mean)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(z_pca[:, 0], z_pca[:, 1], c=y, cmap='viridis')\n",
        "    plt.colorbar()\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Componente Principal 1')\n",
        "    plt.ylabel('Componente Principal 2')\n",
        "    plt.show()\n",
        "\n",
        "# Plot para o Digits Dataset\n",
        "plot_latent_space(encoder, X_digits_scaled, y_digits, 'Espaço Latente - Digits Dataset')\n",
        "\n",
        "# Plot para o Iris Dataset\n",
        "plot_latent_space(encoder, X_iris_scaled, y_iris, 'Espaço Latente - Iris Dataset')"
      ],
      "metadata": {
        "id": "3jJEJwpc-0Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análise dos Resultados\n",
        "\n",
        "1. **Formação de Clusters**: No espaço latente, observamos a formação de clusters para ambos os datasets. No caso do Digits Dataset, os clusters correspondem aos diferentes dígitos, enquanto no Iris Dataset, os clusters correspondem às diferentes espécies de flores.\n",
        "\n",
        "2. **Separação dos Rótulos**: A separação dos rótulos no espaço latente é evidente, especialmente no Iris Dataset, onde as três espécies de flores são bem separadas. No Digits Dataset, alguns dígitos se sobrepõem, o que pode ser devido à similaridade entre eles (por exemplo, os dígitos 1 e 7).\n",
        "\n",
        "3. **Variância Capturada**: A projeção PCA do espaço latente captura uma quantidade significativa da variância dos dados, como evidenciado pela clara separação dos clusters.\n",
        "\n",
        "### Conclusão\n",
        "\n",
        "Neste trabalho, treinamos modelos VAEs em dois datasets diferentes e exploramos o espaço latente gerado. Observamos a formação de clusters e a separação dos rótulos no espaço latente, além de avaliar a variância capturada pela projeção PCA. Os resultados demonstram a eficácia dos VAEs em aprender representações latentes significativas dos dados.\n",
        "\n",
        "---\n",
        "\n",
        "### Adicional (Opcional): Enviesar a Formação do Espaço Latente\n",
        "\n",
        "Para enviesar a formação do espaço latente com os exemplos rotulados, podemos incorporar os rótulos no processo de treinamento do VAE. Isso pode ser feito modificando a função de perda para incluir uma componente que penaliza a distância entre as amostras do mesmo rótulo no espaço latente.\n",
        "\n",
        "# Função de perda modificada para enviesar o espaço latente"
      ],
      "metadata": {
        "id": "9FEiKRug7IL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_loss_with_labels(x, x_decoded_mean):\n",
        "    reconstruction_loss = losses.mse(x, x_decoded_mean)\n",
        "    kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "    label_loss = K.mean(K.square(z_mean[y == y] - z_mean[y == y]))  # Penaliza distância entre amostras do mesmo rótulo\n",
        "    return K.mean(reconstruction_loss + kl_loss + label_loss)\n"
      ],
      "metadata": {
        "id": "Nl3xGoWj_Vyt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}